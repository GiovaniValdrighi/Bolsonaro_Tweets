{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Bolsonaro Tweets Projeto final da disciplina de fundamentos de ci\u00eancia dos dados ministrada pelo professor Jorge Poco na FGV-EMAp. Desde o in\u00edcio da pandemia de Covid-19, observamos cada vez mais o impacto da dissemina\u00e7\u00e3o de informa\u00e7\u00e3o atrav\u00e9s de redes sociais e blogs online. Atrav\u00e9s da credibilidade de certas imagens, como autoridades e famosos, as pessoas constroem suas cren\u00e7as e opini\u00f5es sobre os assuntos. Dentro deste contexto, o Brasil est\u00e1 passando por uma fase em que os ideais pol\u00edticos est\u00e3o se tornando extremamente polarizados. Com o impeachment do \u00faltimo presidente e a quantidade de protestos contra o atual, sites como twitter e facebook est\u00e3o produzindo cada vez mais uma maior quantidade de dados relacionados \u00e0 este tema. Com isso, tweets, em especial os da fam\u00edlia de Jair Bolsonaro (atual presidente do Brasil), s\u00e3o influentes e necess\u00e1rios para diversas an\u00e1lises da situa\u00e7\u00e3o do pa\u00eds, como economia e outros setores. Apesar dos indicadores econ\u00f4micos serem baseados em infinitas vari\u00e1veis latentes, pode-se tentar identificar uma correla\u00e7\u00e3o entre suas varia\u00e7\u00f5es e os tweets.","title":"Home"},{"location":"#bolsonaro-tweets","text":"Projeto final da disciplina de fundamentos de ci\u00eancia dos dados ministrada pelo professor Jorge Poco na FGV-EMAp. Desde o in\u00edcio da pandemia de Covid-19, observamos cada vez mais o impacto da dissemina\u00e7\u00e3o de informa\u00e7\u00e3o atrav\u00e9s de redes sociais e blogs online. Atrav\u00e9s da credibilidade de certas imagens, como autoridades e famosos, as pessoas constroem suas cren\u00e7as e opini\u00f5es sobre os assuntos. Dentro deste contexto, o Brasil est\u00e1 passando por uma fase em que os ideais pol\u00edticos est\u00e3o se tornando extremamente polarizados. Com o impeachment do \u00faltimo presidente e a quantidade de protestos contra o atual, sites como twitter e facebook est\u00e3o produzindo cada vez mais uma maior quantidade de dados relacionados \u00e0 este tema. Com isso, tweets, em especial os da fam\u00edlia de Jair Bolsonaro (atual presidente do Brasil), s\u00e3o influentes e necess\u00e1rios para diversas an\u00e1lises da situa\u00e7\u00e3o do pa\u00eds, como economia e outros setores. Apesar dos indicadores econ\u00f4micos serem baseados em infinitas vari\u00e1veis latentes, pode-se tentar identificar uma correla\u00e7\u00e3o entre suas varia\u00e7\u00f5es e os tweets.","title":"Bolsonaro Tweets"},{"location":"data_scrapping_preprocessing/","text":"Dados Para a realiza\u00e7\u00e3o do projeto s\u00e3o utilizadas dois conjuntos diferentes de dados - tweets dos perfis estudados e s\u00e9ries temporais econ\u00f4micas brasileiras - que devem ser organizadas e preparadas para a posterior utiliza\u00e7\u00e3o na gera\u00e7\u00e3o de visualiza\u00e7\u00e3o, de an\u00e1lises e de modelos. Nessa etapa, ser\u00e3o muito \u00fateis duas APIs, a do Twitter e a do Banco Central do Brasil. Coleta de dados Twitter Os dados do Twitter consiste no hist\u00f3rico de tweets dos perfis do presidente Jair Bolsonaro (@jairbolsonaro), do deputado federal Eduardo Bolsonaro (@bolsonarosp), do senador Fl\u00e1vio Bolsonaro (@flaviobolsonaro) e do vereador Carlos Bolsonaro (@carlosbolsonaro). Al\u00e9m do texto presentes nos tweets, tamb\u00e9m poder\u00e1 ser considerados para o projeto outras informa\u00e7\u00f5es presentes, como a data de postagem, quantidade de retweets, exist\u00eancia de m\u00eddias no tweet, entre outras. Para realizar o acesso, utilizaremos da API do Twitter que permite, entre outras tarefas, a obten\u00e7\u00e3o de tweets atrav\u00e9s de buscas por palavras chaves e tamb\u00e9m a obten\u00e7\u00e3o de tweets atrav\u00e9s do perfil de um usu\u00e1rio, no entanto, uma limita\u00e7\u00e3o \u00e9 o n\u00famero de tweets que podem ser coletados, sendo poss\u00edvel apenas coletar os \u00faltimos 3000 tweets de um determinado perfil. Para realizar as solicita\u00e7\u00f5es para a API usaremos a biblioteca Tweepy , uma biblioteca Python que permite a conex\u00e3o. Com a utiliza\u00e7\u00e3o do Tweepy , criamos um objeto chamado Cursor que facilita a obten\u00e7\u00e3o dos dados em poucas linhas. C\u00f3digo #requesting data from twitter twitter_data = {} for user in ['jairbolsonaro', 'bolsonarosp', 'flaviobolsonaro', 'carlosbolsonaro']: twitter_data[user] = [tweet for tweet in tw.Cursor(api.user_timeline,id=user, tweet_mode =\"extended\").items()] #saving original data with open(\"..//data//tweets//brute_scrapping,pkl\", \"wb+\") as f: pkl.dump(twitter_data, f) S\u00e9ries econ\u00f4micas Para os dados de econ\u00f4micos desejamos obter s\u00e9ries hist\u00f3ricas de indicadores importantes para o mercado brasileiro, que sejam tanto di\u00e1rios, mensais, trimestrais. Inicialmente iremos coletar diversos indicadores que n\u00e3o necessariamente possam apresentar rela\u00e7\u00e3o com os tweets da fam\u00edlia do presidente, mas irermos realizar a an\u00e1lise de rela\u00e7\u00e3o em etapas posteriores do projeto. Para essa segunda coleta, tamb\u00e9m usaremos uma a API, dessa vez oferecida pelo BACEN (Banco Central do Brasil), nela, podemos acessar diferentes s\u00e9ries atrav\u00e9s apenas de um n\u00famero identificador. O c\u00f3digo \u00e9 baseado em um v\u00eddeo do Youtube: C\u00f3digo Quant - Finan\u00e7as Quantitativas , COMO ACESSAR A BASE DE DADOS DO BANCO CENTRAL DO BRASIL COM PYTHON | Python para Investimentos #10 . As s\u00e9ries temporais escolhidas para compor o nosso conjunto de dados est\u00e3o listadas abaixo, tabm\u00e9m est\u00e1 listado sua unidade e o instituto que publica o indicador: IPCA : \u00cdndice nacional de pre\u00e7os ao consumidor-amplo, Var. % mensal, (IBGE). Este \u00edndice mede a varia\u00e7\u00e3o de pre\u00e7os de mercado para o consumidor final e \u00e9 utilizado para medir a infla\u00e7\u00e3o. INPC: \u00cdndice nacional de pre\u00e7os ao consumidor, Var. % mensal, (IBGE). Este \u00edndice mede a varia\u00e7\u00e3o de pre\u00e7os da cesta de consumo da popula\u00e7\u00e3o assalariada com mais baixo rendimento. IGP-M : \u00cdndice geral de pre\u00e7os do mercado, Var. % mensal, (FGV). Este \u00edndice mede a varia\u00e7\u00e3o de pre\u00e7os atrav\u00e9s de outros \u00edndices, do IPCA, INCC, e IPC. Meta SELIC : Taxa b\u00e1sica de juros definida pelo Copom, % a.a., (Copom). CDI : Taxa de juros, % a.d., (Cetip). Taxa de juros para empr\u00e9stimo entre bancos. PIB : Produto Interno Bruto mensal, R\\$ (milh\u00f5es), (BCB-Depec). D\u00f3lar: Taxa de c\u00e2mbio - D\u00f3lar americano (venda), u.m.c/US\\$, (Sisbacen PTAX800). D\u00edvida p\u00fablica: D\u00edvida l\u00edquida do Setor P\u00fablico (%PIB) - Total, %, (BSB - DSTAT). Reserva Internacional: Reserva internacional total di\u00e1ria, US\\$ (milh\u00f5es), (BCB - DSTAT). \u00cdndice de emprego formal, (Mtb). PNADC: Taxa de desocupa\u00e7\u00e3o, %, (IBGE). \u00cdndice de confian\u00e7a do consumidor, (Fecomercio). C\u00f3digo def query_bc(code): url = 'http://api.bcb.gov.br/dados/serie/bcdata.sgs.{}/dados?formato=json'.format(code) df = pd.read_json(url) df['data'] = pd.to_datetime(df['data'], dayfirst=True) df.set_index('data', inplace=True) return df ipca = query_bc(433) ipca.to_csv(\"..\\\\data\\\\economic_index\\\\ipca.csv\", sep = \";\") time.sleep(5) igpm = query_bc(189) igpm.to_csv(\"..\\\\data\\\\economic_index\\\\igpm.csv\", sep = \";\") time.sleep(5) inpc = query_bc(188) inpc.to_csv(\"..\\\\data\\\\economic_index\\\\inpc.csv\", sep = \";\") time.sleep(5) selic_meta = query_bc(432) selic_meta.to_csv(\"..\\\\data\\\\economic_index\\\\selic_meta.csv\", sep = \";\") time.sleep(5) international_reserve = query_bc(13621) international_reserve.to_csv(\"..\\\\data\\\\economic_index\\\\international_reserve.csv\", sep = \";\") time.sleep(5) pnad = query_bc(24369) pnad.to_csv(\"..\\\\data\\\\economic_index\\\\pnad.csv\", sep = \";\") time.sleep(5) cdi = query_bc(12) cdi.to_csv(\"..\\\\data\\\\economic_index\\\\cdi.csv\", sep = \";\") time.sleep(5) gdp = query_bc(4385) gdp.to_csv(\"..\\\\data\\\\economic_index\\\\gdp.csv\", sep = \";\") time.sleep(5) dollar = query_bc(1) dollar.to_csv(\"..\\\\data\\\\economic_index\\\\dollar.csv\", sep = \";\") time.sleep(5) employment = query_bc(25239) employment.to_csv(\"..\\\\data\\\\economic_index\\\\employment.csv\", sep = \";\") time.sleep(5) gov_debt = query_bc(4503) gov_debt.to_csv(\"..\\\\data\\\\economic_index\\\\gov_debt.csv\", sep = \";\") time.sleep(5) consumer_confidence = query_bc(4393) consumer_confidence.to_csv(\"..\\\\data\\\\economic_index\\\\consumer_confidence.csv\", sep = \";\") time.sleep(5) Depois de obtida todas as s\u00e9ries, vamos gerar um dataframe final incluindo todas as s\u00e9ries temporais econ\u00f4micas, existir\u00e3o c\u00e9lulas vazias pois os indicadores econ\u00f4micos apresentam frequ\u00eancias diferentes e tamb\u00e9m os indicadores come\u00e7aram a ser calculados em momentos distintos na hist\u00f3ria. Pr\u00e9-processamento dos dados Em sequ\u00eancia da coleta de dados, iremos realizar o pr\u00e9-processamento dos dados para apresenta-los em um resultado adequado para a an\u00e1lise explorat\u00f3ria e para o desenvolvimento de modelos. Entre todas as vari\u00e1veis retornadas pela API do Twitter, iremos selecionar aquelas que podem ser utilizadas no desenvolvimento do projeto. As informa\u00e7\u00f5es selecionadas para compor o conjunto de dados processado ser\u00e3o as seguintes (e os nomes presente no dataframe ): Nome do usus\u00e1rio que postou o tweet (name). Data de cria\u00e7\u00e3o do tweet (created_at). Texto completo do tweet (full_text). Hashtags presentes no tweet (hashtags). Men\u00e7\u00f5es a usu\u00e1rios presentes no tweet (user_mentions). Tipo de m\u00eddia presente no tweet, se h\u00e1 m\u00eddia (media_type). Se o tweet \u00e9 um reply (status_reply). N\u00famero de retweets que o tweet recebeu (retweet_count). N\u00fam\u00e9ro de likes que o tweet recebeu (favorite_count). C\u00f3digo #create dataframe from tweets data tweets_dict = {} columns_list = ['created_at', 'full_text', 'hashtags', 'user_mentions', 'media_type', 'status_reply','name', 'retweet_count', 'favorite_count'] for var in columns_list: tweets_dict[var] = [] for user in ['jairbolsonaro', 'bolsonarosp', 'flaviobolsonaro', 'carlosbolsonaro']: for tweet in tweets_data[user]: for var in columns_list: if var == 'hashtags': aux = '/'.join([u['text'] for u in tweet._json['entities'][var]]) if aux == \"\": tweets_dict[var].append(\"None\") else: tweets_dict[var].append(aux) elif var == \"user_mentions\": aux = '/'.join([u['screen_name'] for u in tweet._json['entities'][var]]) if aux== \"\": tweets_dict[var].append(\"None\") else: tweets_dict[var].append(aux) elif var == \"status_reply\": tweets_dict[var].append(1 if tweet._json['in_reply_to_status_id'] != None else 0) elif var == \"name\": tweets_dict[var].append(user) elif var == \"media_type\": if 'media' in list(tweet._json['entities'].keys()): tweets_dict[var].append(tweet._json['extended_entities']['media'][0]['type']) else: tweets_dict[var].append(None) else: tweets_dict[var].append(tweet._json[var]) tweets_df = pd.DataFrame(tweets_dict) Em seguida, iremos criar vari\u00e1veis extras a partir da vari\u00e1vel da data de postagem do tweet, a apresenta\u00e7\u00e3o das data dessa maneira permite express\u00f5es mais diversas para os modelos. Ser\u00e3o as seguintes: Ano de postagem (year). M\u00eas de postagem (month). Dia de postagem (day). Hora de postagem (hour). Minuto de postagem (minute). Dia da semana de postagem (weekday). Essas vari\u00e1veis auxiliar\u00e3o para o processo de modelagem. Al\u00e9m delas, iremos criar vari\u00e1veis indicadoras (isto \u00e9, assume o valor 0 ou 1), que ser\u00e3o: Se o tweet possui hashtags (has_hashtags). Se o tweet possui men\u00e7\u00f5es (has_mentions). Se o tweet possui alguma m\u00eddia (has_midia). C\u00f3digo tweets_df['date'] = pd.to_datetime(tweets_df.created_at) tweets_df['year'] = tweets_df.date.apply(lambda x : x.year) tweets_df['month'] = tweets_df.date.apply(lambda x : x.month) tweets_df['day'] = tweets_df.date.apply(lambda x : x.day) tweets_df['hour'] = tweets_df.date.apply(lambda x : x.hour) tweets_df['minute'] = tweets_df.date.apply(lambda x : x.minute) tweets_df['weekday'] = tweets_df.date.apply(lambda x : x.weekday) tweets_df['has_hashtags'] = tweets_df.hashtags.apply(lambda x : 1 if x != \"None\" else 0) tweets_df['has_mentions'] = tweets_df.user_mentions.apply(lambda x : 1 if x != \"None\" else 0) tweets_df['has_media'] = tweets_df.media_type.apply(lambda x : 1 if x != \"None\" else 0) tweets_df.drop(columns = ['created_at'], inplace = True) tweets_df.to_csv(\"..\\\\dataa\\\\tweets\\\\preprocessed_tweets.csv\", sep = \"~\") .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } .scrolldiv { width: 800px; overflow-x: auto; white-space: nowrap; } full_text hashtags user_mentions media_type status_reply name retweet_count favorite_count date year month day hour minute weekday has_hashtags has_mentions has_media 0 -Edif\u00edcio Joelma/SP, 1974.\\n\\n-Sgt CASSANIGA s... None None video 0 jairbolsonaro 3154 16202 2020-07-27 20:51:13+00:00 2020 7 27 20 51 0 0 0 1 1 - \u00c1gua para quem tem sede.\\n- Liberdade para u... None None video 0 jairbolsonaro 8101 37357 2020-07-27 11:10:36+00:00 2020 7 27 11 10 0 0 0 1 2 @tarcisiogdf @MInfraestrutura \ud83e\udd1d\ud83c\udde7\ud83c\uddf7, Ministro! None tarcisiogdf/MInfraestrutura NaN 1 jairbolsonaro 1074 16840 2020-07-26 20:18:19+00:00 2020 7 26 20 18 6 0 1 1 3 2- @MinEconomia @MinCidadania @onyxlorenzoni @... None MinEconomia/MinCidadania/onyxlorenzoni/MEC_Com... photo 1 jairbolsonaro 1337 6383 2020-07-26 15:40:39+00:00 2020 7 26 15 40 6 0 1 1 4 1- Acompanhe as redes sociais! @secomvc @fabio... None secomvc/fabiofaria5555/tarcisiogdf/MInfraestru... photo 0 jairbolsonaro 3287 14836 2020-07-26 15:39:47+00:00 2020 7 26 15 39 6 0 1 1 Acesse os notebooks completos da coleta de dados e do pr\u00e9-processamento no Github.","title":"Dados"},{"location":"data_scrapping_preprocessing/#dados","text":"Para a realiza\u00e7\u00e3o do projeto s\u00e3o utilizadas dois conjuntos diferentes de dados - tweets dos perfis estudados e s\u00e9ries temporais econ\u00f4micas brasileiras - que devem ser organizadas e preparadas para a posterior utiliza\u00e7\u00e3o na gera\u00e7\u00e3o de visualiza\u00e7\u00e3o, de an\u00e1lises e de modelos. Nessa etapa, ser\u00e3o muito \u00fateis duas APIs, a do Twitter e a do Banco Central do Brasil.","title":"Dados"},{"location":"data_scrapping_preprocessing/#coleta-de-dados","text":"","title":"Coleta de dados"},{"location":"data_scrapping_preprocessing/#twitter","text":"Os dados do Twitter consiste no hist\u00f3rico de tweets dos perfis do presidente Jair Bolsonaro (@jairbolsonaro), do deputado federal Eduardo Bolsonaro (@bolsonarosp), do senador Fl\u00e1vio Bolsonaro (@flaviobolsonaro) e do vereador Carlos Bolsonaro (@carlosbolsonaro). Al\u00e9m do texto presentes nos tweets, tamb\u00e9m poder\u00e1 ser considerados para o projeto outras informa\u00e7\u00f5es presentes, como a data de postagem, quantidade de retweets, exist\u00eancia de m\u00eddias no tweet, entre outras. Para realizar o acesso, utilizaremos da API do Twitter que permite, entre outras tarefas, a obten\u00e7\u00e3o de tweets atrav\u00e9s de buscas por palavras chaves e tamb\u00e9m a obten\u00e7\u00e3o de tweets atrav\u00e9s do perfil de um usu\u00e1rio, no entanto, uma limita\u00e7\u00e3o \u00e9 o n\u00famero de tweets que podem ser coletados, sendo poss\u00edvel apenas coletar os \u00faltimos 3000 tweets de um determinado perfil. Para realizar as solicita\u00e7\u00f5es para a API usaremos a biblioteca Tweepy , uma biblioteca Python que permite a conex\u00e3o. Com a utiliza\u00e7\u00e3o do Tweepy , criamos um objeto chamado Cursor que facilita a obten\u00e7\u00e3o dos dados em poucas linhas. C\u00f3digo #requesting data from twitter twitter_data = {} for user in ['jairbolsonaro', 'bolsonarosp', 'flaviobolsonaro', 'carlosbolsonaro']: twitter_data[user] = [tweet for tweet in tw.Cursor(api.user_timeline,id=user, tweet_mode =\"extended\").items()] #saving original data with open(\"..//data//tweets//brute_scrapping,pkl\", \"wb+\") as f: pkl.dump(twitter_data, f)","title":"Twitter"},{"location":"data_scrapping_preprocessing/#series-economicas","text":"Para os dados de econ\u00f4micos desejamos obter s\u00e9ries hist\u00f3ricas de indicadores importantes para o mercado brasileiro, que sejam tanto di\u00e1rios, mensais, trimestrais. Inicialmente iremos coletar diversos indicadores que n\u00e3o necessariamente possam apresentar rela\u00e7\u00e3o com os tweets da fam\u00edlia do presidente, mas irermos realizar a an\u00e1lise de rela\u00e7\u00e3o em etapas posteriores do projeto. Para essa segunda coleta, tamb\u00e9m usaremos uma a API, dessa vez oferecida pelo BACEN (Banco Central do Brasil), nela, podemos acessar diferentes s\u00e9ries atrav\u00e9s apenas de um n\u00famero identificador. O c\u00f3digo \u00e9 baseado em um v\u00eddeo do Youtube: C\u00f3digo Quant - Finan\u00e7as Quantitativas , COMO ACESSAR A BASE DE DADOS DO BANCO CENTRAL DO BRASIL COM PYTHON | Python para Investimentos #10 . As s\u00e9ries temporais escolhidas para compor o nosso conjunto de dados est\u00e3o listadas abaixo, tabm\u00e9m est\u00e1 listado sua unidade e o instituto que publica o indicador: IPCA : \u00cdndice nacional de pre\u00e7os ao consumidor-amplo, Var. % mensal, (IBGE). Este \u00edndice mede a varia\u00e7\u00e3o de pre\u00e7os de mercado para o consumidor final e \u00e9 utilizado para medir a infla\u00e7\u00e3o. INPC: \u00cdndice nacional de pre\u00e7os ao consumidor, Var. % mensal, (IBGE). Este \u00edndice mede a varia\u00e7\u00e3o de pre\u00e7os da cesta de consumo da popula\u00e7\u00e3o assalariada com mais baixo rendimento. IGP-M : \u00cdndice geral de pre\u00e7os do mercado, Var. % mensal, (FGV). Este \u00edndice mede a varia\u00e7\u00e3o de pre\u00e7os atrav\u00e9s de outros \u00edndices, do IPCA, INCC, e IPC. Meta SELIC : Taxa b\u00e1sica de juros definida pelo Copom, % a.a., (Copom). CDI : Taxa de juros, % a.d., (Cetip). Taxa de juros para empr\u00e9stimo entre bancos. PIB : Produto Interno Bruto mensal, R\\$ (milh\u00f5es), (BCB-Depec). D\u00f3lar: Taxa de c\u00e2mbio - D\u00f3lar americano (venda), u.m.c/US\\$, (Sisbacen PTAX800). D\u00edvida p\u00fablica: D\u00edvida l\u00edquida do Setor P\u00fablico (%PIB) - Total, %, (BSB - DSTAT). Reserva Internacional: Reserva internacional total di\u00e1ria, US\\$ (milh\u00f5es), (BCB - DSTAT). \u00cdndice de emprego formal, (Mtb). PNADC: Taxa de desocupa\u00e7\u00e3o, %, (IBGE). \u00cdndice de confian\u00e7a do consumidor, (Fecomercio). C\u00f3digo def query_bc(code): url = 'http://api.bcb.gov.br/dados/serie/bcdata.sgs.{}/dados?formato=json'.format(code) df = pd.read_json(url) df['data'] = pd.to_datetime(df['data'], dayfirst=True) df.set_index('data', inplace=True) return df ipca = query_bc(433) ipca.to_csv(\"..\\\\data\\\\economic_index\\\\ipca.csv\", sep = \";\") time.sleep(5) igpm = query_bc(189) igpm.to_csv(\"..\\\\data\\\\economic_index\\\\igpm.csv\", sep = \";\") time.sleep(5) inpc = query_bc(188) inpc.to_csv(\"..\\\\data\\\\economic_index\\\\inpc.csv\", sep = \";\") time.sleep(5) selic_meta = query_bc(432) selic_meta.to_csv(\"..\\\\data\\\\economic_index\\\\selic_meta.csv\", sep = \";\") time.sleep(5) international_reserve = query_bc(13621) international_reserve.to_csv(\"..\\\\data\\\\economic_index\\\\international_reserve.csv\", sep = \";\") time.sleep(5) pnad = query_bc(24369) pnad.to_csv(\"..\\\\data\\\\economic_index\\\\pnad.csv\", sep = \";\") time.sleep(5) cdi = query_bc(12) cdi.to_csv(\"..\\\\data\\\\economic_index\\\\cdi.csv\", sep = \";\") time.sleep(5) gdp = query_bc(4385) gdp.to_csv(\"..\\\\data\\\\economic_index\\\\gdp.csv\", sep = \";\") time.sleep(5) dollar = query_bc(1) dollar.to_csv(\"..\\\\data\\\\economic_index\\\\dollar.csv\", sep = \";\") time.sleep(5) employment = query_bc(25239) employment.to_csv(\"..\\\\data\\\\economic_index\\\\employment.csv\", sep = \";\") time.sleep(5) gov_debt = query_bc(4503) gov_debt.to_csv(\"..\\\\data\\\\economic_index\\\\gov_debt.csv\", sep = \";\") time.sleep(5) consumer_confidence = query_bc(4393) consumer_confidence.to_csv(\"..\\\\data\\\\economic_index\\\\consumer_confidence.csv\", sep = \";\") time.sleep(5) Depois de obtida todas as s\u00e9ries, vamos gerar um dataframe final incluindo todas as s\u00e9ries temporais econ\u00f4micas, existir\u00e3o c\u00e9lulas vazias pois os indicadores econ\u00f4micos apresentam frequ\u00eancias diferentes e tamb\u00e9m os indicadores come\u00e7aram a ser calculados em momentos distintos na hist\u00f3ria.","title":"S\u00e9ries econ\u00f4micas"},{"location":"data_scrapping_preprocessing/#pre-processamento-dos-dados","text":"Em sequ\u00eancia da coleta de dados, iremos realizar o pr\u00e9-processamento dos dados para apresenta-los em um resultado adequado para a an\u00e1lise explorat\u00f3ria e para o desenvolvimento de modelos. Entre todas as vari\u00e1veis retornadas pela API do Twitter, iremos selecionar aquelas que podem ser utilizadas no desenvolvimento do projeto. As informa\u00e7\u00f5es selecionadas para compor o conjunto de dados processado ser\u00e3o as seguintes (e os nomes presente no dataframe ): Nome do usus\u00e1rio que postou o tweet (name). Data de cria\u00e7\u00e3o do tweet (created_at). Texto completo do tweet (full_text). Hashtags presentes no tweet (hashtags). Men\u00e7\u00f5es a usu\u00e1rios presentes no tweet (user_mentions). Tipo de m\u00eddia presente no tweet, se h\u00e1 m\u00eddia (media_type). Se o tweet \u00e9 um reply (status_reply). N\u00famero de retweets que o tweet recebeu (retweet_count). N\u00fam\u00e9ro de likes que o tweet recebeu (favorite_count). C\u00f3digo #create dataframe from tweets data tweets_dict = {} columns_list = ['created_at', 'full_text', 'hashtags', 'user_mentions', 'media_type', 'status_reply','name', 'retweet_count', 'favorite_count'] for var in columns_list: tweets_dict[var] = [] for user in ['jairbolsonaro', 'bolsonarosp', 'flaviobolsonaro', 'carlosbolsonaro']: for tweet in tweets_data[user]: for var in columns_list: if var == 'hashtags': aux = '/'.join([u['text'] for u in tweet._json['entities'][var]]) if aux == \"\": tweets_dict[var].append(\"None\") else: tweets_dict[var].append(aux) elif var == \"user_mentions\": aux = '/'.join([u['screen_name'] for u in tweet._json['entities'][var]]) if aux== \"\": tweets_dict[var].append(\"None\") else: tweets_dict[var].append(aux) elif var == \"status_reply\": tweets_dict[var].append(1 if tweet._json['in_reply_to_status_id'] != None else 0) elif var == \"name\": tweets_dict[var].append(user) elif var == \"media_type\": if 'media' in list(tweet._json['entities'].keys()): tweets_dict[var].append(tweet._json['extended_entities']['media'][0]['type']) else: tweets_dict[var].append(None) else: tweets_dict[var].append(tweet._json[var]) tweets_df = pd.DataFrame(tweets_dict) Em seguida, iremos criar vari\u00e1veis extras a partir da vari\u00e1vel da data de postagem do tweet, a apresenta\u00e7\u00e3o das data dessa maneira permite express\u00f5es mais diversas para os modelos. Ser\u00e3o as seguintes: Ano de postagem (year). M\u00eas de postagem (month). Dia de postagem (day). Hora de postagem (hour). Minuto de postagem (minute). Dia da semana de postagem (weekday). Essas vari\u00e1veis auxiliar\u00e3o para o processo de modelagem. Al\u00e9m delas, iremos criar vari\u00e1veis indicadoras (isto \u00e9, assume o valor 0 ou 1), que ser\u00e3o: Se o tweet possui hashtags (has_hashtags). Se o tweet possui men\u00e7\u00f5es (has_mentions). Se o tweet possui alguma m\u00eddia (has_midia). C\u00f3digo tweets_df['date'] = pd.to_datetime(tweets_df.created_at) tweets_df['year'] = tweets_df.date.apply(lambda x : x.year) tweets_df['month'] = tweets_df.date.apply(lambda x : x.month) tweets_df['day'] = tweets_df.date.apply(lambda x : x.day) tweets_df['hour'] = tweets_df.date.apply(lambda x : x.hour) tweets_df['minute'] = tweets_df.date.apply(lambda x : x.minute) tweets_df['weekday'] = tweets_df.date.apply(lambda x : x.weekday) tweets_df['has_hashtags'] = tweets_df.hashtags.apply(lambda x : 1 if x != \"None\" else 0) tweets_df['has_mentions'] = tweets_df.user_mentions.apply(lambda x : 1 if x != \"None\" else 0) tweets_df['has_media'] = tweets_df.media_type.apply(lambda x : 1 if x != \"None\" else 0) tweets_df.drop(columns = ['created_at'], inplace = True) tweets_df.to_csv(\"..\\\\dataa\\\\tweets\\\\preprocessed_tweets.csv\", sep = \"~\") .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } .scrolldiv { width: 800px; overflow-x: auto; white-space: nowrap; } full_text hashtags user_mentions media_type status_reply name retweet_count favorite_count date year month day hour minute weekday has_hashtags has_mentions has_media 0 -Edif\u00edcio Joelma/SP, 1974.\\n\\n-Sgt CASSANIGA s... None None video 0 jairbolsonaro 3154 16202 2020-07-27 20:51:13+00:00 2020 7 27 20 51 0 0 0 1 1 - \u00c1gua para quem tem sede.\\n- Liberdade para u... None None video 0 jairbolsonaro 8101 37357 2020-07-27 11:10:36+00:00 2020 7 27 11 10 0 0 0 1 2 @tarcisiogdf @MInfraestrutura \ud83e\udd1d\ud83c\udde7\ud83c\uddf7, Ministro! None tarcisiogdf/MInfraestrutura NaN 1 jairbolsonaro 1074 16840 2020-07-26 20:18:19+00:00 2020 7 26 20 18 6 0 1 1 3 2- @MinEconomia @MinCidadania @onyxlorenzoni @... None MinEconomia/MinCidadania/onyxlorenzoni/MEC_Com... photo 1 jairbolsonaro 1337 6383 2020-07-26 15:40:39+00:00 2020 7 26 15 40 6 0 1 1 4 1- Acompanhe as redes sociais! @secomvc @fabio... None secomvc/fabiofaria5555/tarcisiogdf/MInfraestru... photo 0 jairbolsonaro 3287 14836 2020-07-26 15:39:47+00:00 2020 7 26 15 39 6 0 1 1 Acesse os notebooks completos da coleta de dados e do pr\u00e9-processamento no Github.","title":"Pr\u00e9-processamento dos dados"}]}